{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0be59ab6-58d1-4729-8f71-1e0159842f45",
   "metadata": {},
   "source": [
    "# SPARRA data examples\n",
    "\n",
    "Done in python for speed -- if you want to export the resulting dataframes, go for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cd7849-22f2-495e-b60a-d19564c2a019",
   "metadata": {},
   "source": [
    "## PIS\n",
    "\n",
    "Each row is a prescription payment _event_. Each prescription event is characterised by a BNF section (see e.g. https://openprescribing.net/bnf/), a date, and a number of items. Features might be things like:\n",
    "1. Number of distinct BNF sections for an ID\n",
    "2. Count of items that come from one of a set of BNF sections\n",
    "3. Total number of items across all BNF sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e119cf5-3d8e-4392-84ab-1a9500f34a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  paid_date bnf_section  num_items\n",
      "0   0 2017-11-27        0104          2\n",
      "1   8 2015-08-24        0101          5\n",
      "2   9 2018-01-01        0103          1\n",
      "3   2 2017-06-24        0106          3\n",
      "4   2 2016-12-16        0201          3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def random_dates(start, end, n, seed=1, replace=False):\n",
    "    dates = pd.date_range(start, end).to_series()\n",
    "    return list(dates.sample(n, replace=replace, random_state=seed))\n",
    "\n",
    "MAX_ID = 10 # 10 different people\n",
    "N_ROWS = 100 # lots of rows\n",
    "START = pd.to_datetime('2015-01-01')\n",
    "END = pd.to_datetime('2018-01-01')\n",
    "id_vals = np.random.choice(MAX_ID, N_ROWS)\n",
    "BNF_SECS = [\n",
    "    '0101',\n",
    "    '0102',\n",
    "    '0103',\n",
    "    '0104',\n",
    "    '0105',\n",
    "    '0106',\n",
    "    '0107',\n",
    "    '0108',\n",
    "    '0109',\n",
    "    '0201',\n",
    "    '0202',\n",
    "    '0203',\n",
    "    '0204' # etc - got bored typing them in\n",
    "]\n",
    "date_vals = random_dates(START, END, n=N_ROWS, replace=True)\n",
    "bnf_vals = np.random.choice(BNF_SECS, N_ROWS)\n",
    "num_items_vals = np.random.poisson(2, N_ROWS) + 1 # don't want zeros\n",
    "pis_data = pd.DataFrame({'id': id_vals, 'paid_date': date_vals, 'bnf_section': bnf_vals, 'num_items': num_items_vals}, index=range(N_ROWS))\n",
    "print(pis_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484a03e-3ad0-408a-bc09-5c8ff99f8c33",
   "metadata": {},
   "source": [
    "### Example PIS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1390d7a-aa5e-4c79-85e9-9e35a0832a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  n_distinct_bnf\n",
      "0   0               6\n",
      "1   1               8\n",
      "2   2               6\n",
      "3   3               7\n",
      "4   4               5\n",
      "   id  n_total_items\n",
      "0   0             21\n",
      "1   1             36\n",
      "2   2             22\n",
      "3   3             41\n",
      "4   4             31\n",
      "   id  n_diar_and_anti\n",
      "0   0                4\n",
      "1   1                7\n",
      "2   3                4\n",
      "3   4                6\n",
      "4   7                4\n"
     ]
    }
   ],
   "source": [
    "# distinct bnf\n",
    "n_distinct = pis_data.groupby('id').agg(n_distinct_bnf = pd.NamedAgg(column='bnf_section', aggfunc='nunique')).reset_index()\n",
    "print(n_distinct.head())\n",
    "# total prescribed items\n",
    "total_items = pis_data.groupby('id').agg(n_total_items = pd.NamedAgg(column='num_items', aggfunc='sum')).reset_index()\n",
    "print(total_items.head())\n",
    "# particular BNF (total prescribed items after some filtering on section)\n",
    "pis_diar_and_anti = pis_data.loc[pis_data['bnf_section'].isin(['0203','0204']), :].groupby('id').agg(n_diar_and_anti = pd.NamedAgg(column='num_items', aggfunc='sum')).reset_index()\n",
    "print(pis_diar_and_anti.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85116be1-e568-472a-920a-4141219354fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bac8582-801b-46e0-97f9-e52d59aa7be1",
   "metadata": {},
   "source": [
    "## SMR04 (psych admissions -- example where there are multiple episodes per stay)\n",
    "\n",
    "Bit harder to generate, so simple simulation\n",
    "\n",
    "- Each row is an _episode_. Multiple episodes make up a stay.\n",
    "- The `cis_marker` field can be used to group episodes from one id into a stay. I.e. all rows for a (`id`, `cis_marker`) tuple correspond to a single stay.\n",
    "- `episode_within_cis` tells us the order of the episodes within a stah\n",
    "- I've added a random code to show what the features might be like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "68f59410-4033-4cef-b6f5-54ac0bf2d97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id admission_date discharge_date  cis_marker  episode_within_cis some_code\n",
      "0   3     2017-11-17     2017-11-17          17                   1         e\n",
      "1   5     2016-03-11     2016-03-12          50                   1         c\n",
      "2   6     2017-12-10     2017-12-11          83                   1         b\n",
      "3   6     2017-12-11     2017-12-14          83                   2         e\n",
      "4   6     2017-12-14     2017-12-14          83                   3         a\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "N_STAYS = 100\n",
    "start_dates = random_dates(START, END, n=N_STAYS, seed=1, replace=False)\n",
    "data_dict = {'id': [], 'admission_date': [], 'discharge_date': [], 'cis_marker': [], 'episode_within_cis': [], 'some_code': []}\n",
    "cis_dict = {}\n",
    "# Generate 100 stays in total\n",
    "for stay_idx in range(N_STAYS):\n",
    "    # pick a start date for the stay\n",
    "    start_date = start_dates[stay_idx]\n",
    "\n",
    "    # pick an ID for the stay\n",
    "    id = np.random.choice(MAX_ID, 1)[0]\n",
    "\n",
    "    # decide how many episodes to generate\n",
    "    n_episodes = np.random.poisson(1) + 1 # + 1 so we don't get zero\n",
    "\n",
    "    # Take the next cis_marker (cis = continuous integrated stay)\n",
    "    # or generate a random starting marker if we haven't hit this ID before\n",
    "    # Note that the absolute value of the cis_marker is irrelevant\n",
    "    # also Note that cis_marker values are not unique across the population, only\n",
    "    # within a particular ID\n",
    "    if id in cis_dict:\n",
    "        cis_marker = cis_dict[id] + 1\n",
    "        cis_dict[id] += 1\n",
    "    else:\n",
    "        cis_marker = np.random.choice(100) + 1\n",
    "        cis_dict[id] = cis_marker\n",
    "\n",
    "    # loop over the episodes\n",
    "    for episode in range(n_episodes):\n",
    "        episode_within_cis = episode + 1 # first episode in a stay has episode_within_cis = 1\n",
    "        # First episode has stay start date as its start\n",
    "        episode_start_date = start_date\n",
    "\n",
    "        # Pick a duration in days (this can be zero as an episode might not take the whole day)\n",
    "        episode_duration = np.random.poisson(1)\n",
    "        episode_end_date = episode_start_date + timedelta(days=episode_duration)\n",
    "\n",
    "        # Set start_date for the next episode to the end date of this one\n",
    "        start_date = episode_end_date\n",
    "\n",
    "        # Add a random code just to demonstrate the kind of features we might want\n",
    "        code = np.random.choice(['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "        # Add the episode to the data dictionary\n",
    "        data_dict['id'].append(id)\n",
    "        data_dict['admission_date'].append(episode_start_date)\n",
    "        data_dict['discharge_date'].append(episode_end_date)\n",
    "        data_dict['episode_within_cis'].append(episode_within_cis)\n",
    "        data_dict['some_code'].append(code)\n",
    "        data_dict['cis_marker'].append(cis_marker)\n",
    "\n",
    "# Put everything into a dataframe\n",
    "smr04 = pd.DataFrame(data_dict, index=range(len(data_dict['id'])))\n",
    "print(smr04.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7d8d7a-b548-4901-a536-afb1156f8756",
   "metadata": {},
   "source": [
    "### Example SMR04 features\n",
    "\n",
    "Just some examples to hopefully cover the kind of things SPARRA uses.\n",
    "\n",
    "Note one thing I haven't shown here -- sometimes for episodic data like this you have to be careful when doing _date filtering_. I.e. SPARRA only includes information for _stays_ that start within the relevant time period. Therefore you cannot simply filter on episodes dates, but you need to either:\n",
    "1. Keep all episodes where the first episode in the stay is within the date range, or\n",
    "2. Merge into stays first and then filter.\n",
    "\n",
    "To transform to one row per stay, you'd need to do things like take the admission date from the first episode and the discharge from the last etc.\n",
    "\n",
    "Note that some SPARRA features count stay-related things based on codes in their first episode (stays are classified as emergency / elective based just on information in their first episode) and some things based on the code appearing in any episode (alcohol related stays are counted as the number of stays where _any_ episode within the stay has an alcohol diagnosis code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fc2daf07-555d-4cc9-8b22-bb99eb4768b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  n_stays\n",
      "0   0       14\n",
      "1   1       10\n",
      "2   2        3\n",
      "3   3       12\n",
      "4   4       10\n",
      "   id total_bed_days\n",
      "0   0        19 days\n",
      "1   1        31 days\n",
      "2   2         4 days\n",
      "3   3        22 days\n",
      "4   4        18 days\n",
      "   id  n_stays_b\n",
      "0   0          4\n",
      "1   1          2\n",
      "2   2          1\n",
      "3   3          2\n",
      "4   4          1\n"
     ]
    }
   ],
   "source": [
    "# number of stays per id\n",
    "# (lots of ways of calculating this) -- this is one example: count the distinct cis_marker\n",
    "n_stays = smr04.groupby('id').agg(n_stays = pd.NamedAgg(column='cis_marker', aggfunc='nunique')).reset_index()\n",
    "print(n_stays.head())\n",
    "# total nights in hospital\n",
    "smr04['length_of_stay'] = smr04['discharge_date'] - smr04['admission_date']\n",
    "n_bed_days = smr04.groupby('id').agg(total_bed_days = pd.NamedAgg(column='length_of_stay', aggfunc='sum')).reset_index()\n",
    "print(n_bed_days.head())\n",
    "# number of stays where the first episode had code 'b'\n",
    "n_stays_b = smr04.loc[(smr04['some_code'] == 'b') & (smr04['episode_within_cis'] == 1), :].groupby('id').agg(n_stays_b = pd.NamedAgg(column='cis_marker', aggfunc='nunique')).reset_index()\n",
    "print(n_stays_b.head())\n",
    "# number of bed days for stays where any episode has code 'c'\n",
    "# ran out of time to implement -- but basically need to keep all _stays_ where _any_ episode in the stay has a code c and then compute number of bed days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb6dcd-3bb8-4a4c-9331-664c493f112b",
   "metadata": {},
   "source": [
    "# SPARRA LTC\n",
    "\n",
    "This one is a bit different (but will work). The data has one row per ID and one column per Long Term Condition. The values are NA if the person does not have that LTC and the date they were first diagnosed if they do. There are 19 conditions. I've just done 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c3d41a82-3fed-4c59-96e3-3661d055a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['ASTHMA', 'DIABETES', 'PARKINSONS']\n",
    "data_dict = {'id': [], 'ASTHMA': [], 'DIABETES': [], 'PARKINSONS': []}\n",
    "start_dates = random_dates(START, END, n=MAX_ID*3, seed=1, replace=True)\n",
    "date_pos = 0\n",
    "for i in range(MAX_ID):\n",
    "    data_dict['id'].append(i)\n",
    "    for c_pos in range(len(conditions)):\n",
    "        if np.random.rand() < 0.2:\n",
    "            # they have this condition\n",
    "            dat = start_dates[date_pos]\n",
    "            date_pos += 1\n",
    "            data_dict[conditions[c_pos]].append(dat)\n",
    "        else:\n",
    "            data_dict[conditions[c_pos]].append(np.NaN)\n",
    "ltc_data = pd.DataFrame(data_dict, index=range(MAX_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8b18c706-59a4-4ec0-add6-6e7d098367d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ASTHMA</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>PARKINSONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2015-08-24</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2017-06-24</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     ASTHMA   DIABETES PARKINSONS\n",
       "0   0 2017-11-27        NaT        NaT\n",
       "1   1        NaT 2015-08-24        NaT\n",
       "2   2        NaT        NaT 2018-01-01\n",
       "3   3        NaT 2017-06-24        NaT\n",
       "4   4        NaT        NaT        NaT\n",
       "5   5        NaT        NaT        NaT\n",
       "6   6        NaT 2016-12-16        NaT\n",
       "7   7        NaT        NaT        NaT\n",
       "8   8        NaT 2017-04-27        NaT\n",
       "9   9        NaT        NaT        NaT"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltc_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69c8d29-28db-4cfd-896a-dc6d6eb49dc6",
   "metadata": {},
   "source": [
    "Exmaple features:\n",
    "1. Years since the LTC diagnosis date (null if no date) - one feature per lTC so there would be three in this case: years_since_asthma, years_since_diabetes etc\n",
    "2. Number of LTCs (i.e. number of non-null values for each id (row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47439ff3-31eb-4b26-b5f3-a311153afcbc",
   "metadata": {},
   "source": [
    "## Indicated features\n",
    "These combine PIS and LTC. E.g. for a particular ID, feature starts with value 0. If they have any prescriptions in a set of BNF sections, then add 1. If they have a particular LTC date, then add 1. So value will be 0, 1, 2. There are five of these -- each with different BNF and LTC combinations.\n",
    "\n",
    "This is the example where I think we'd want to be able to specify features in the json that combine multiple inputs, and the inputs would be the output of other transformations.\n",
    "\n",
    "E.g. transform 1: do they have a prescritpion in some BNF section(s) (1 = yes, 0 = no)\n",
    "transform 2: do they have a date in a particular LTC (1 = yes, 0 = no)\n",
    "transform 3: transform 1 + transform 2 (per id)\n",
    "\n",
    "Concrete example, BNF = 0201 and LTC = diabetes. So, need a transformation that computes a \"has_0201\" feature (0 or 1 depending if theyhave any 0201 PIS rows or now) and a has_diabetes feature (0 or 1 depending if they have null, or a date in LTC)\n",
    "\n",
    "We would then need a third transformer that would ADD the has_0201 and has_diabetes feature for each id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a3504-3deb-42d5-a57c-0e50da2c62c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
